#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Assigns GHI to the pairs/triples generated by preprocess.py.

Input (searched in this order; the first one that exists wins):
  • data/processed/pairs_both.csv   (complete triples: BRBG+CDOC)
  • data/processed/pairs_brbg.csv   (pairs; includes CDOC per-row if available)
  • data/processed/pairs.csv        (LEGACY: raw_path + mask_path)

Output:
  • data/processed/pairs_with_ghi_full.csv with columns:
      raw_path, mask_brbg_path, mask_cdoc_path, stamp, ghi

Usage:
  caffeinate -d -i python src/extract_ghi_for_pairs.py
"""

import os
import re
import pandas as pd
from pathlib import Path

DATA_DIR = Path("data/processed")
IRR_CSV  = DATA_DIR / "irradiance_clamped.csv"
OUT_CSV  = DATA_DIR / "pairs_with_ghi_full.csv"

CANDIDATES = [
    DATA_DIR / "pairs_both.csv",
    DATA_DIR / "pairs_brbg.csv",
    DATA_DIR / "pairs.csv",  # legacy
]

STAMP_RE = re.compile(r"(\d{14})")


def extract_stamp(path: str) -> str:
    """Extract 'YYYYMMDDhhmmss' from the filename."""
    base = os.path.basename(str(path))
    m = STAMP_RE.search(base)
    return m.group(1) if m else ""


def _load_pairs() -> pd.DataFrame:
    """
    Load the best available pairs/triples CSV, normalizing column names to a unified schema:
      - Ensures 'mask_brbg_path' exists (renames legacy 'mask_path' if needed).
      - Adds empty 'mask_cdoc_path' if not present (CDOC is optional per row).
      - Requires 'raw_path'.
    Raises:
      FileNotFoundError if none of the candidate CSVs exist.
      ValueError for missing required columns.
    """
    src = None
    for c in CANDIDATES:
        if c.exists():
            src = c
            break
    if src is None:
        raise FileNotFoundError(
            "None found: pairs_both.csv / pairs_brbg.csv / pairs.csv under data/processed/"
        )

    print(f"→ Loading pairs from: {src}")
    df = pd.read_csv(src)

    # Normalize columns to unified schema
    if "mask_path" in df.columns and "mask_brbg_path" not in df.columns:
        df = df.rename(columns={"mask_path": "mask_brbg_path"})
    if "mask_brbg_path" not in df.columns:
        raise ValueError(f"The CSV {src} does not contain 'mask_brbg_path' (nor legacy 'mask_path').")

    if "mask_cdoc_path" not in df.columns:
        df["mask_cdoc_path"] = ""  # empty if there is no CDOC for that row

    if "raw_path" not in df.columns:
        raise ValueError(f"The CSV {src} does not contain 'raw_path'.")

    return df


def main():
    # 1) Load pairs/triples
    pairs = _load_pairs()
    print(f"→ Pairs loaded: {len(pairs)} rows")

    # 2) Ensure/extract 'stamp' (14-digit string)
    if "stamp" in pairs.columns:
        pairs["stamp"] = pairs["stamp"].astype(str).str.extract(STAMP_RE)[0]
    else:
        pairs["stamp"] = pairs["raw_path"].astype(str).apply(extract_stamp)

    n_missing_stamp = pairs["stamp"].isna().sum() + (pairs["stamp"] == "").sum()
    if n_missing_stamp:
        print(f"Rows without an extractable stamp: {n_missing_stamp}. They will be dropped before merging.")
        pairs = pairs[pairs["stamp"].notna() & (pairs["stamp"] != "")].copy()

    print(f"→ Unique stamps: {pairs['stamp'].nunique()} out of {len(pairs)} rows")

    # 3) Load clamped irradiance table
    if not IRR_CSV.exists():
        raise FileNotFoundError(f"Missing {IRR_CSV}. Generate irradiance_clamped.csv first.")
    irr = pd.read_csv(IRR_CSV, dtype={"stamp": str})
    irr["stamp"] = irr["stamp"].astype(str).str.extract(STAMP_RE)[0]
    irr = irr[irr["stamp"].notna()].copy()
    print(f"→ Irradiance records: {len(irr)} rows (with valid stamp)")

    # 4) Left-merge on 'stamp' (many pairs to one irradiance row)
    merged = pd.merge(
        pairs,
        irr[["stamp", "ghi"]],
        on="stamp",
        how="left",
        validate="m:1",
    )
    print(f"→ After merge: {len(merged)} rows | missing GHI: {merged['ghi'].isna().sum()}")

    # 5) Save useful columns (in order)
    cols = ["raw_path", "mask_brbg_path", "mask_cdoc_path", "stamp", "ghi"]
    for c in cols[:-1]:
        if c not in merged.columns:
            merged[c] = ""  # safety net

    merged[cols].to_csv(OUT_CSV, index=False)
    print(f"Final CSV saved to {OUT_CSV}")


if __name__ == "__main__":
    main()
